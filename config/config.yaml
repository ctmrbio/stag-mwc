# vim: syntax=python expandtab
#
#     StaG Metagenomic Workflow Collaboration
#                 configuration file
#
# Configuration settings marked with [Required] are required if the pipeline
# step for that setting is included. Set which steps to include under the
# "Pipeline steps included" heading. The default settings are to only run read
# preprocessing steps.


#########################
# Run configuration
#########################
inputdir: "input"
input_fn_pattern: "{sample}_{readpair}.fq.gz"
samplesheet: ""           # Three-column samplesheet with sample_id,fastq_1,fastq_2 columns. Used instead of inputdir
outdir: "output_dir"
logdir: "output_dir/logs"
report: "StaG_report-"    # Filename prefix for report file ("-{datetime}.html" automatically appended)
email: ""                 # Email to send status message after completed/failed run.


#########################
# Remote services
#########################
s3_endpoint_url: "https://s3.ki.se"  # Use https://s3.amazonaws.com for Amazon S3
keep_local: False                    # Keep local copies of remote input files, default False.


#########################
# Container images
#########################
containers:
    bbmap: "docker://quay.io/biocontainers/bbmap:39.06--h92535d8_0"
    bowtie2: "docker://quay.io/biocontainers/bowtie2:2.5.1--py38he00c5e5_2"
    bracken: "docker://quay.io/biocontainers/bracken:2.9--py39h1f90b4d_0"
    fastp: "docker://quay.io/biocontainers/fastp:0.23.4--hadf994f_2"
    humann: "docker://quay.io/biocontainers/humann:3.8--pyh7cba7a3_0"
    kaiju: "docker://quai.io/biocontainers/kaiju:1.10.1--h43eeafb_0"
    kraken2: "docker://quay.io/biocontainers/kraken2:2.1.3--pl5321hdcf5f25_0"
    krakenuniq: "docker://quay.io/biocontainers/krakenuniq:1.0.4--pl5321h6dccd9a_1"
    krona: "docker://quay.io/biocontainers/krona:2.8.1--pl5321hdfd78af_1"
    metaphlan: "docker://quay.io/biocontainers/metaphlan:4.1.0--pyhca03a8a_0"
    multiqc: "docker://quay.io/biocontainers/multiqc:1.21--pyhdfd78af_0"
    samtools: "docker://quay.io/biocontainers/samtools:1.19.2--h50ea8bc_1"
    stag: "oras://ghcr.io/ctmrbio/stag-mwc:stag-mwc-develop"


#########################
# Pipeline steps included
#########################
qc_reads: True
host_removal: 
    kraken2: True
    bowtie2: False
multiqc_report: True
naive:
    assess_depth: False
    sketch_compare: False
taxonomic_profile:
    kaiju: False
    kraken2: False
    krakenuniq: False
    metaphlan: False
strain_level_profiling:
    strainphlan: False    # Will also run metaphlan. Please make sure you've added bt2_db_dir and bt2_index under metaphlan settings.
functional_profile:
    humann: False         # Will also run metaphlan. Please make sure you've added bt2_db_dir and bt2_index under metaphlan settings.
mappers:
    bbmap: False
    bowtie2: False


#########################
# Preprocessing
#########################
fastp:
    extra: ""
    keep_output: False       # StaG deletes fastp output files after host removal, set to True to keep them.
remove_host:
    kraken2:
        db_path: ""              # [Required] Path to folder containing a Kraken2 database with host sequences (taxo.k2d, etc.)
        confidence: 0.1          # Kraken2 confidence score, float in [0,1]
        extra: "--quick"         # Additional command line arguments to kraken2
        keep_kraken: False       # Keep the kraken files for host removal, set to False to remove them automatically.
        keep_kreport: False      # Keep the kreport files for host removal, set to False to remove them automatically.
        keep_fastq: True         # Keep the host-removed fastq files, set to False to remove them automatically.
        keep_host_fastq: False   # Keep the host-containing fastq files, set to False to remove them automatically.
    bowtie2:
        db_path: ""              # [Required] Path to bowtie2 database to use for host removal, including database filename prefix (no .1.bt2 etc)
        extra: "--sensitive"
        keep_fastq: True         # Keep the host-removed fastq files, set to False to remove them automatically.
multiqc:
    extra: ""


#########################
# Naive sample analyses
#########################
bbcountunique:
    interval: 5000           # Typically set to 10000, but test data requires <=5035


#########################
# Taxonomic profiling
#########################
kaiju:
    db: ""                   # [Required] Path to Kaiju DB file
    nodes: ""                # [Required] Path to Kaiju taxonomy nodes.dmp
    names: ""                # [Required] Path to Kaiju taxonomy names.dmp
    levels: ["species", "genus", "family"]    # Level(s) to summarize Kaiju report to, pick from: superkingdom, phylum, class, order, family, genus, species
    feature_column: "taxon_name"   # Feature column to use in all_samples summary
    value_column: "percent"        # Value column top use in all_samples summary. Options are typically "percent" or "reads"
    run_krona: True

kraken2:
    db: ""                   # [Required] Path to Kraken2 DB folder
    confidence: 0.1          # Kraken2 confidence score, float in [0,1]
    minimum_hit_groups: 2    # Integer, default 2
    extra: ""                # Extra command line arguments for kraken2 (do not add/change output files)
    keep_kraken: False       # Keep the kraken output files
    keep_kreport: True       # Keep the kreport output files
    run_krona: True
    bracken:
        kmer_distrib: ""     # [Required for Bracken] Path to kmer_distrib file for Kraken2 DB specified above
        levels: "S G"        # Space-separated list of taxonomic levels to produce tables for (e.g. "F G S" for Family, Genus, Species)
        thresh: 10           # Threshold for minimum number of reads from Kraken
    filter_bracken:          # Arguments to filter_bracken_out.py to include/exclude certain taxa
        include: ""
        exclude: "--exclude 9605 9606"  # Taxid 9605 and 9606 are (G) Homo and (S) Homo sapiens

krakenuniq:
    db: ""                   # [Required] Path to KrakenUniq DB folder
    preload_size: "128G"     # Max amount of RAM to use when loading database (will automatically chunk DB to fit)
    extra: ""                # Extra command line arguments for krakenuniq (do not add/change output files)
    keep_kraken: False       # Keep the kraken output files
    keep_kreport: True       # Keep the kreport output files
    run_krona: True


metaphlan:
    bt2_db_dir: ""           # [Required] Path to MetaPhlAn database dir
    bt2_index: ""            # [Required] Name of MetaPhlAn database index
    extra: ""                # Extra command line arguments for MetaPhlAn e.g. "-t rel_ab_w_read_stats"
    keep_bt2: False          # Keep the bowtie2 files
    keep_sam: False          # Keep the sam files, set this to True if you want to run StrainPhlAn.
    run_krona: True
    heatmap:
        create_plot: True        # Whether to create the MetaPhlAn heatmap plot, set to False to disable
        level: "Species"         # Taxononomic level: Kingdom, Phylum, Class, Order, Family, Genus, Species, or Strain
        topN: 50                 # Number of top taxa to include in heatmap.
        pseudocount: -1          # Negative value means to autocompute pseudocount
        colormap: "viridis"      # Standard matplotlib and seaborn colormaps
        method: "average"        # Linkage method, see scipy.cluster.hierarchy.linkage
        metric: "braycurtis"     # Distrance metric to use
        extra: ""                # Extra params, mostly to set loglevel to DEBUG in case of problems.

#########################
# Strain Level Profiling 
#########################
strainphlan:
    clade_of_interest: ""    # [Required] e.g. s__Bifidobacterium_longum
    mode: "accurate"
    extra: ""

#########################
# Functional profiling
#########################
humann:
    nucleotide_db: ""        # [Required] Path to ChocoPhlAn DB directory.
    protein_db: ""           # [Required] Path to protein database directory (typically UniRef90).
    utility_db: ""           # [Required] Path to utility_mapping database.
    norm_method: "cpm"       # Normalization scheme: copies per million [cpm], relative abundance [relab]; default=[cpm].
    norm_mode: "community"   # Normalization mode, Normalize all levels by [community] total or [levelwise] totals; default=[community].
    extra: ""                # Extra command line arguments for humann e.g. --bypass-translated-search

#########################
# Mappers
#########################
bbmap:
    - db_name: ""              # [Required] Custom name for BBMap database
      db_path: ""              # [Required] Path to BBMap database (folder should contain a 'ref' folder)
      min_id: 0.76             # Minimum id for read alignment, BBMap default is 0.76
      keep_sam: False          # Set to True to keep intermediary SAM file
      keep_bam: True           # Set to False to remove bam files after counting annotations
      extra: ""                # Extra BBMap command line parameters
      counts_table:
          annotations: ""      # Tab-separated annotation file with headers, first column is full FASTA header of reference sequences
          columns: ""          # Column names in header of annotation file to include summaries of
      featureCounts:
          annotations: ""      # [Required] Full path to GTF format annotations for database sequences. If not set, featureCounts summary will be skipped.
          feature_type: ""     # Feature type to produce counts for, default is "gene"
          attribute_type: ""   # Attribute type to summarize counts for, default is "gene_id" (any attribute in the GTF file's attribute field can be used)
          extra: ""            # Extra featureCount command line parameters
bowtie2:
    - db_prefix: ""            # [Required] Full path to Bowtie2 index (not including file extension)
      keep_bam: True           # Set to False to remove bam files after counting annotations
      extra: ""                # Extra bowtie2 commandline parameters
      counts_table:
          annotations: ""      # Tab-separated annotation file with headers, first column is full FASTA header of reference sequences
          columns: ""          # Column names in header of annotation file to include summaries of
      featureCounts:
          annotations: ""      # [Required] Full path to GTF format annotations for database sequences. If not set, featureCounts summary will be skipped.
          feature_type: ""     # Feature type to produce counts for, default is "gene"
          attribute_type: ""   # Attribute type to summarize counts for, default is "gene_id" (any attribute in the GTF file's attribute field can be used)
          extra: ""            # Extra featureCount command line parameters

